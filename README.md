ğŸ“š Simple PDF-based RAG System with Ollama (LLaMA 3.2)
A minimal, local-first Retrieval-Augmented Generation (RAG) system powered by Ollama's LLaMA 3.2 model, capable of answering questions by retrieving contextually relevant content from PDF documents.

This project showcases how to load PDF documents, split them into searchable chunks, embed them into a vector database (ChromaDB), and perform query-time retrieval with augmented LLM responses using LangChain.

ğŸš€ Features
ğŸ”¥ Local LLaMA 3.2 model served via Ollama

ğŸ“„ PDF ingestion and text chunking

ğŸ—‚ï¸ Vector embedding and storage via ChromaDB

ğŸ’¬ Multi-query retriever for improved document search accuracy

ğŸ“– Context-augmented query answering

ğŸ›ï¸ Interactive UI built with Streamlit

ğŸ“¦ Clean, extensible, lightweight codebase

ğŸ“¦ Tech Stack
Python 3.x

Ollama (for LLaMA 3.2 & text embeddings)

LangChain

ChromaDB

Streamlit

PyPDFLoader (LangChain Community)

RecursiveCharacterTextSplitter

MultiQueryRetriever

Sentence Transformers (embedding support)

ğŸ› ï¸ Setup & Installation
1ï¸âƒ£ Install Ollama (if not already)
bash
Copy
Edit
curl -fsSL https://ollama.com/install.sh | sh
Start the Ollama service:

bash
Copy
Edit
ollama serve
2ï¸âƒ£ Install Python dependencies
Create and activate a virtual environment:

bash
Copy
Edit
python3 -m venv venv
source venv/bin/activate
Then install the required packages:

bash
Copy
Edit
pip install -r requirements.txt
Note: Youâ€™ll need a PDF file at ./data/BOI.pdf or adjust DOC_PATH in app.py.

ğŸ›ï¸ How to Run
Start the Streamlit app:

bash
Copy
Edit
streamlit run app.py
Then open http://localhost:8501 in your browser.

âœ¨ How It Works
ğŸ“– PDF loaded using PyPDFLoader.

ğŸ“œ Text split into overlapping chunks via RecursiveCharacterTextSplitter.

ğŸ§  Text chunks embedded with Ollama Embeddings using nomic-embed-text.

ğŸ“Š Stored and retrieved from a Chroma vector database.

ğŸ” User queries are expanded into multiple variants with MultiQueryRetriever.

ğŸ’¬ Retrieved context + query passed to LLaMA 3.2 for answer generation.

ğŸ›ï¸ Interactive results displayed via Streamlit UI.

ğŸ“„ Dependencies
Key dependencies:

css
Copy
Edit
ollama
chromadb
pdfplumber
langchain
langchain-core
langchain-ollama
langchain-community
langchain_text_splitters
unstructured
unstructured[all-docs]
fastembed
pikepdf
sentence-transformers
elevenlabs
ğŸ“Œ Project Structure
bash
Copy
Edit
.
â”œâ”€â”€ app.py                # Streamlit app and RAG pipeline
â”œâ”€â”€ data/
â”‚   â””â”€â”€ BOI.pdf           # Example PDF document
â”œâ”€â”€ chroma_db/            # Persistent vector database directory
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project description
ğŸ“– Future Improvements
ğŸ“š Multi-PDF document support

ğŸ“ˆ Vector store performance optimization

ğŸ“ Summarization and PDF metadata parsing

ğŸ“Š Usage analytics and session history

ğŸ“¢ Credits
Built by Prazwal as a clean, local-first implementation of a PDF-based RAG system using Ollama and LangChain.

ğŸ”’ License
This project is open-source and available under the MIT License
